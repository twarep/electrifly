{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a program which is in testing phase. We will use a linear regression ML model to give an SOC number for the flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the querying module\n",
    "from flight_querying import query_flights\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set up and retrieve the data from the database.\n",
    "db_connect = query_flights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the data dictionary holder\n",
    "data_dict = {\n",
    "    \"Time Delta\": [],\n",
    "    \"SOC Delta\": [],\n",
    "    \"Activity\": [],\n",
    "    \"Average Power\": [],\n",
    "    \"Id\": [],\n",
    "    \"Unique Data Identifier\": [],\n",
    "    \"temperature\": [],\n",
    "    \"Visibility\": [],\n",
    "    \"Wind Speed\": []\n",
    "}\n",
    "\n",
    "# Create a increasing int variable to keep track of the Unique Data Identifier\n",
    "unique_identifier = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_parser(parsing_dataframe):\n",
    "\n",
    "    global unique_identifier\n",
    "    # Get the current exercise\n",
    "    current_exercise = parsing_dataframe.iloc[0, parsing_dataframe.columns.get_loc('activity')]\n",
    "    id = parsing_dataframe.iloc[0, parsing_dataframe.columns.get_loc('id')]\n",
    "    max_soc, min_soc = 0, 101\n",
    "    power_list = [0]\n",
    "    min_time, max_time = 100, 0\n",
    "\n",
    "    # iterate over all the rows\n",
    "    for index, row in parsing_dataframe.iterrows():\n",
    "\n",
    "        # Get the data needed from the rows. Append the power\n",
    "        new_exercise = row[\"activity\"]\n",
    "        soc = row[\"soc\"]\n",
    "        power_list.append(row[\"power\"])\n",
    "        time = row[\"time\"]\n",
    "        outside_temp = row[\"temperature\"]\n",
    "        visibility = row[\"visibility\"]\n",
    "        wind_speed = row[\"wind_speed\"]\n",
    "\n",
    "        # If the exercise changes or if the rows end.\n",
    "        if current_exercise != new_exercise or index == len(parsing_dataframe) - 1:\n",
    "\n",
    "            # Set the values \n",
    "            data_dict[\"Time Delta\"].append(round(max_time - min_time, 2))\n",
    "            data_dict[\"SOC Delta\"].append(max_soc - min_soc)\n",
    "            data_dict[\"Activity\"].append(current_exercise)\n",
    "            data_dict[\"Average Power\"].append(round(sum(power_list)/len(power_list), 2))\n",
    "            data_dict[\"temperature\"].append(outside_temp)\n",
    "            data_dict[\"Visibility\"].append(visibility)\n",
    "            data_dict[\"Wind Speed\"].append(wind_speed)\n",
    "            data_dict[\"Id\"].append(id)\n",
    "            data_dict[\"Unique Data Identifier\"].append(unique_identifier)\n",
    "            unique_identifier = unique_identifier + 1\n",
    "\n",
    "            # Reset all the values\n",
    "            max_soc, min_soc = soc, soc\n",
    "            power_list.clear()\n",
    "            max_time, min_time = time, time\n",
    "        \n",
    "        # SOC\n",
    "        if soc >= max_soc:\n",
    "            max_soc = soc\n",
    "        if soc <= min_soc:\n",
    "            min_soc = soc\n",
    "\n",
    "        # TIME\n",
    "        if time >= max_time:\n",
    "            max_time = time\n",
    "        if time <= min_time:\n",
    "            min_time = time\n",
    "        \n",
    "        # Change current exercise\n",
    "        current_exercise = new_exercise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight IDs to include\n",
    "# query the list of flight ids excluding these six which are already labelled\n",
    "flight_ids = db_connect.get_flight_ids()\n",
    "flight_ids = flight_ids['id'].to_list()\n",
    "ids_avoid = [5190, 5192, 5109]\n",
    "\n",
    "# remove the manually_labelled_ids from the list \n",
    "flight_ids = [id for id in flight_ids if id not in ids_avoid]\n",
    "print(flight_ids)\n",
    "# Fetch data for specified flight IDs\n",
    "# Remove NA values from each dataframe in the list and put it through the data parser\n",
    "for ids in flight_ids:\n",
    "    frame = db_connect.connect_flight_for_ml_data_prescription(ids)\n",
    "    frame = frame[frame[\"activity\"] != \"NA\"].reset_index()\n",
    "    if len(frame) > 0:\n",
    "      data_parser(frame)\n",
    "    else:\n",
    "      print(ids)\n",
    "\n",
    "# Concatenate data frames and shuffle the data\n",
    "# all_data = pd.concat(data_frames, axis=0).sample(frac=1, random_state=42)\n",
    "all_data = pd.DataFrame(data_dict).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(all_data, test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length train_x = {len(train_data)} \\n Length train_y = {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot-Encoding of the Operations columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODE\n",
    "# https://stackabuse.com/one-hot-encoding-in-python-with-pandas-and-scikit-learn/\n",
    "def one_hot(df, col, pre):\n",
    "  encoded = pd.get_dummies(df[col], prefix=pre)\n",
    "  for column in encoded:\n",
    "    encoded = encoded.rename(columns={column: col + \"_\" + column})\n",
    "  encoded['Unique Data Identifier'] = df['Unique Data Identifier']\n",
    "  return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Train data\n",
    "train_encoded = one_hot(train_data, \"Activity\", 'is')\n",
    "final_train_x = pd.merge(train_data, train_encoded, on=[\"Unique Data Identifier\"])\n",
    "final_train_y = final_train_x[\"SOC Delta\"].to_numpy()\n",
    "final_train_x = final_train_x.drop(columns=[\"SOC Delta\", \"Id\", \"Unique Data Identifier\", \"Activity\"])\n",
    "\n",
    "# Encode Test data\n",
    "test_encoded = one_hot(test_data, \"Activity\", 'is')\n",
    "final_test_x = pd.merge(test_data, test_encoded, on=[\"Unique Data Identifier\"])\n",
    "final_test_y = final_test_x[\"SOC Delta\"].to_numpy()\n",
    "final_test_x = final_test_x.drop(columns=[\"SOC Delta\", \"Id\", \"Unique Data Identifier\", \"Activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length test_encoded = {len(test_encoded)} \\n Length train_encoded = {len(train_encoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length train_x = {len(final_train_x)} \\n Length train_y = {len(final_train_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length test_x = {len(final_test_x)} \\n Length test_y = {len(final_test_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set model\n",
    "regression_model = LinearRegression()\n",
    "# Fit model\n",
    "regression_model.fit(final_train_x, final_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if there is no power on stall activities in test set, add the column with all false values\n",
    "if 'Activity_is_power on stall' not in final_test_x.columns:\n",
    "  final_test_x.insert(loc=final_test_x.columns.get_loc('Activity_is_slow flight'), column='Activity_is_power on stall', value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "y_pred = regression_model.predict(final_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print model score\n",
    "print(regression_model.score(final_test_x, final_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.5f\" % mean_squared_error(final_test_y, y_pred))\n",
    "\n",
    "# The coefficient of determination: 1 is perfect prediction\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(final_test_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(final_test_y, y_pred, color=\"black\")\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.DataFrame(list(zip(regression_model.feature_names_in_, regression_model.coef_)), columns = ['Feature', 'Weight'])\n",
    "coeff.sort_values('Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "model_filename = 'ML_model_outputs/prescription_linreg_model.joblib'\n",
    "joblib.dump(regression_model, model_filename)\n",
    "\n",
    "print(f\"Model saved to {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
